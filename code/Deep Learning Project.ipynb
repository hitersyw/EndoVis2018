{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used for JHU CS 482/682: Deep Learning 2019 Spring Project\n",
    "# Copyright: Zhaoshuo Li, Ding Hao, Mingyi Zheng\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import transforms\n",
    "from dataset import *\n",
    "from visualization import *\n",
    "from label_conversion import *\n",
    "from dice_loss import *\n",
    "from model_trainning import *\n",
    "from model_pretrainning import *\n",
    "\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed pytorch and numpy and random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# must seed the same value each time when training a new network\n",
    "seed = 256\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "pretrain_seed = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 70\n",
    "num_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.ones((num_class,1))\n",
    "weights = weights.to(device)\n",
    "dice_loss = DICELoss(weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the visualization environment\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = unet(useBN=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Scheduler and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize optimizer and lr decay\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# must seed the same value each time when training a new network\n",
    "seed = 256\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "train_dataset=MICCAIDataset(data_type = \"train\", transform=None)\n",
    "validation_dataset=MICCAIDataset(data_type = \"validation\", transform=None)\n",
    "label_converter = LabelConverter()\n",
    "\n",
    "# # show one example\n",
    "# img,label = train_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# colorlabel = train_dataset.label_converter.label2color(label.permute(1,2,0))\n",
    "# imshow(colorlabel)\n",
    "\n",
    "# # show one example\n",
    "# img,label = validation_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# colorlabel = train_dataset.label_converter.label2color(label.permute(1,2,0))\n",
    "# imshow(colorlabel)\n",
    "\n",
    "# intialize the dataloader\n",
    "train_generator = DataLoader(train_dataset,shuffle=True,batch_size=train_batch_size,num_workers=8)\n",
    "validation_generator = DataLoader(validation_dataset,shuffle=True,batch_size=validation_batch_size,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_wts = run_training(model,device,num_class,scheduler,optimizer,dice_loss,num_epochs,train_generator,train_dataset,validation_generator,validation_dataset,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "## save model\n",
    "torch.save(model.state_dict(), 'vanilla_trained_unet_new_dice.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "test_dataset=MICCAIDataset(data_type = \"test\", transform=None)\n",
    "test_generator=DataLoader(test_dataset,shuffle=False,batch_size=4,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load('vanilla_trained_unet_new_dice.pt'))\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dice = test(model,device,dice_loss,num_class,test_generator,test_dataset,writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# must seed the same value each time when training a new network\n",
    "seed = 256\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "pretrain_seed = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "train_dataset=MICCAIDataset(data_type = \"train\", transform=transforms)\n",
    "validation_dataset=MICCAIDataset(data_type = \"validation\", transform=None)\n",
    "label_converter = LabelConverter()\n",
    "\n",
    "# # show one example\n",
    "# img,label = train_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# colorlabel = train_dataset.label_converter.label2color(label.permute(1,2,0))\n",
    "# imshow(colorlabel)\n",
    "\n",
    "# # show one example\n",
    "# img,label = validation_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# colorlabel = train_dataset.label_converter.label2color(label.permute(1,2,0))\n",
    "# imshow(colorlabel)\n",
    "\n",
    "# intialize the dataloader\n",
    "train_generator = DataLoader(train_dataset,shuffle=True,batch_size=train_batch_size,num_workers=8)\n",
    "validation_generator = DataLoader(validation_dataset,shuffle=True,batch_size=validation_batch_size,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = run_training(model,device,num_class,scheduler,optimizer,dice_loss,num_epochs,train_generator,train_dataset,validation_generator,validation_dataset,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "## save model\n",
    "torch.save(model.state_dict(), 'aug_trained_unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load('aug_trained_unet.pt'))\n",
    "model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "test_dataset=MICCAIDataset(data_type = \"test\", transform=None)\n",
    "test_generator=DataLoader(test_dataset,shuffle=False,batch_size=4,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dice = test(model,device,dice_loss,num_class,test_generator,test_dataset,writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation Pretraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# must seed the same value each time when training a new network\n",
    "pretrain_seed = 128\n",
    "random.seed(pretrain_seed)\n",
    "torch.manual_seed(pretrain_seed)\n",
    "np.random.seed(pretrain_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "num_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain model generated\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = unet_pretrain(useBN=True)\n",
    "pretrain_model.to(device)\n",
    "print(\"pretrain model generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize optimizer and lr decay and loss\n",
    "optimizer = torch.optim.Adam(pretrain_model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "pretrain_dataset=Transformation_PretrainDataset(data_type = \"train\", transform=None)\n",
    "prevalidation_dataset=Transformation_PretrainDataset(data_type = \"validation\", transform=None)\n",
    "label_converter = LabelConverter()\n",
    "\n",
    "# # show one example\n",
    "# img,label = pretrain_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# imshow(label.permute(1,2,0),denormalize=True)\n",
    "\n",
    "# # show one example\n",
    "# img,label = validation_dataset.__getitem__(0)\n",
    "# imshow(img.permute(1,2,0),denormalize=True)\n",
    "# colorlabel = train_dataset.label_converter.label2color(label.permute(1,2,0))\n",
    "# imshow(colorlabel)\n",
    "\n",
    "# intialize the dataloader\n",
    "pretrain_generator = DataLoader(pretrain_dataset,shuffle=True,batch_size=train_batch_size,num_workers=8)\n",
    "prevalidation_generator = DataLoader(prevalidation_dataset,shuffle=True,batch_size=validation_batch_size,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training Started!\n",
      "\n",
      "EPOCH 1 of 30\n",
      "\n",
      "Epoch Loss: 0.1408\n",
      "----------\n",
      "Vaildation Loss: 0.1515\n",
      "\n",
      "EPOCH 2 of 30\n",
      "\n",
      "Epoch Loss: 0.1216\n",
      "----------\n",
      "Vaildation Loss: 0.1350\n",
      "\n",
      "EPOCH 3 of 30\n",
      "\n",
      "Epoch Loss: 0.1199\n",
      "----------\n",
      "Vaildation Loss: 0.1247\n",
      "\n",
      "EPOCH 4 of 30\n",
      "\n",
      "Epoch Loss: 0.1206\n",
      "----------\n",
      "Vaildation Loss: 0.1262\n",
      "\n",
      "EPOCH 5 of 30\n",
      "\n",
      "Epoch Loss: 0.1185\n",
      "----------\n",
      "Vaildation Loss: 0.1418\n",
      "\n",
      "EPOCH 6 of 30\n",
      "\n",
      "Epoch Loss: 0.1189\n",
      "----------\n",
      "Vaildation Loss: 0.1134\n",
      "\n",
      "EPOCH 7 of 30\n",
      "\n",
      "Epoch Loss: 0.1156\n",
      "----------\n",
      "Vaildation Loss: 0.1151\n",
      "\n",
      "EPOCH 8 of 30\n",
      "\n",
      "Epoch Loss: 0.1162\n",
      "----------\n",
      "Vaildation Loss: 0.1146\n",
      "\n",
      "EPOCH 9 of 30\n",
      "\n",
      "Epoch Loss: 0.1158\n",
      "----------\n",
      "Vaildation Loss: 0.1286\n",
      "\n",
      "EPOCH 10 of 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_wts = run_pretraining(pretrain_model,device,scheduler,optimizer,criterion,num_epochs,pretrain_generator,pretrain_dataset,prevalidation_generator,prevalidation_dataset,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load best model weights\n",
    "pretrain_model.load_state_dict(best_model_wts)\n",
    "## save model\n",
    "torch.save(pretrain_model.state_dict(), 'pre_trained_unet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tune network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(useBN=True)\n",
    "model.load_state_dict(pretrain_model.state_dict())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 70\n",
    "num_class = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# must seed the same value each time when training a new network\n",
    "seed = 256\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize optimizer and lr decay\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = run_training(model,device,num_class,scheduler,optimizer,dice_loss,num_epochs,train_generator,train_dataset,validation_generator,validation_dataset,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
